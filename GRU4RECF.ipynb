{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU4REC-F\n",
    "\n",
    "This notebook trains models from `models.py` on the input data, and evaluates their performance. \n",
    "\n",
    "It's set to train GRU4REC-F (our proposed non-attentive model) by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar 23 08:39:11 2021\n",
    "\n",
    "@author: lpott\n",
    "\"\"\"\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing import *\n",
    "from dataset import *\n",
    "from metrics import *\n",
    "from model import *\n",
    "from utils import bert2dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "read_filename =\"data/movielens-1m/ratings.dat\"\n",
    "read_bert_filename = \"data/bert_sequence_1m.txt\"\n",
    "read_movie_filename = \"\"#\"movies-1m.csv\"\n",
    "size = \"1m\"\n",
    "\n",
    "num_epochs = 50\n",
    "lr =  0.005#0.01\n",
    "lr_alternate = 0.001#0.001\n",
    "batch_size = 64\n",
    "reg = 3e-5 # was 1e-5 before\n",
    "train_method = \"alternate\"\n",
    "loss_type = \"BPR_MAX\"\n",
    "num_neg_samples = 25\n",
    "reg_bpr = 0\n",
    "\n",
    "\n",
    "hidden_dim = 512\n",
    "embedding_dim = 512\n",
    "bert_dim= 768\n",
    "window = 0\n",
    "\n",
    "freeze_plot = False\n",
    "tied = False\n",
    "dropout= 0\n",
    "\n",
    "k = 10\n",
    "max_length = 200\n",
    "min_len = 5\n",
    "\n",
    "\n",
    "# nextitnet options...\n",
    "hidden_layers = 3\n",
    "dilations = [1,2,4,16]\n",
    "\n",
    "model_type = \"feature_add\"\n",
    "\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Creating DataFrame ==========\n",
      "user_id        6040\n",
      "item_id        3706\n",
      "rating            5\n",
      "timestamp    458455\n",
      "dtype: int64\n",
      "(1000209, 4)\n",
      "Minimum Session Length: 20\n",
      "Maximum Session Length: 2314\n",
      "Average Session Length: 165.60\n",
      "========== Filtering Sessions <= 5  DataFrame ==========\n",
      "user_id        6040\n",
      "item_id        3416\n",
      "rating            5\n",
      "timestamp    458254\n",
      "dtype: int64\n",
      "(999611, 4)\n",
      "Minimum Session Length: 18\n",
      "Maximum Session Length: 2277\n",
      "Average Session Length: 165.50\n",
      "Average Item User Appearances 292.63\n"
     ]
    }
   ],
   "source": [
    "# ------------------Data Initialization----------------------#\n",
    "\n",
    "# convert .dat file to time-sorted pandas dataframe\n",
    "ml_1m = create_df(read_filename,size=size)\n",
    "\n",
    "# remove users who have sessions lengths less than min_len\n",
    "ml_1m = filter_df(ml_1m,item_min=min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Initialize Reset DataFrame Object ==========\n",
      "========== Resetting user ids and item ids in DataFrame ==========\n"
     ]
    }
   ],
   "source": [
    "# ------------------Data Initialization----------------------#\n",
    "if read_movie_filename != \"\":\n",
    "    ml_movie_df = create_movie_df(read_movie_filename,size=size)\n",
    "    ml_movie_df = convert_genres(ml_movie_df)\n",
    "    \n",
    "    # initialize reset object\n",
    "    reset_object = reset_df()\n",
    "    \n",
    "    # map all user ids, item ids, and genres to range 0 - number of users/items/genres\n",
    "    ml_1m,ml_movie_df = reset_object.fit_transform(ml_1m,ml_movie_df)\n",
    "    \n",
    "    # value that padded genre tokens shall take\n",
    "    pad_genre_token = reset_object.genre_enc.transform([\"NULL\"]).item()\n",
    "    \n",
    "    genre_dim = len(np.unique(np.concatenate(ml_movie_df.genre))) - 1\n",
    "\n",
    "else:\n",
    "    # initialize reset object\n",
    "    reset_object = reset_df()\n",
    "    \n",
    "    # map all user ids and item ids to range 0 - Number of Users/Items \n",
    "    # i.e. [1,7,5] -> [0,2,1]\n",
    "    ml_1m = reset_object.fit_transform(ml_1m)\n",
    "    \n",
    "    pad_genre_token = None\n",
    "    ml_movie_df = None\n",
    "    genre_dim = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Reading .txt file with all item id and embeddings ==========\n"
     ]
    }
   ],
   "source": [
    "# ------------------Data Initialization----------------------#\n",
    "# how many unique users, items, ratings and timestamps are there\n",
    "n_users,n_items,n_ratings,n_timestamp = ml_1m.nunique()\n",
    "\n",
    "# value that padded tokens shall take\n",
    "pad_token = n_items\n",
    "\n",
    "# the output dimension for softmax layer\n",
    "output_dim = n_items\n",
    "\n",
    "\n",
    "# get the item id : bert plot embedding dictionary\n",
    "if bert_dim != 0:\n",
    "    feature_embed = bert2dict(bert_filename=read_bert_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 92/6040 [00:00<00:06, 912.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Creating User Histories ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:06<00:00, 936.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of every user's session (history)\n",
    "# i.e. {user: [user clicks]}\n",
    "if size == \"1m\":\n",
    "    user_history = create_user_history(ml_1m)\n",
    "\n",
    "elif size == \"20m\":\n",
    "    import pickle\n",
    "    with open('userhistory.pickle', 'rb') as handle:\n",
    "        user_history = pickle.load(handle)\n",
    "# create a dictionary of all items a user has not clicked\n",
    "# i.e. {user: [items not clicked by user]}\n",
    "# user_noclicks = create_user_noclick(user_history,ml_1m,n_items)\n",
    "# with open('filename.pickle', 'wb') as handle:\n",
    "#     pickle.dump(user_history, 'userhistory.pickle', protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:00<00:00, 133237.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Splitting User Histories into Train, Validation, and Test Splits ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# split data by leave-one-out strategy\n",
    "# have train dictionary {user: [last 41 items prior to last 2 items in user session]}\n",
    "# have val dictionary {user: [last 41 items prior to last item in user session]}\n",
    "# have test dictionary {user: [last 41 items]}\n",
    "# i.e. if max_length = 4, [1,2,3,4,5,6] -> [1,2,3,4] , [2,3,4,5] , [3,4,5,6]\n",
    "train_history,val_history,test_history = train_val_test_split(user_history,max_length=max_length)\n",
    "\n",
    "# initialize the train,validation, and test pytorch dataset objects\n",
    "# eval pads all items except last token to predict\n",
    "train_dataset = GRUDataset(train_history,genre_df=ml_movie_df,mode='train',max_length=max_length,pad_token=pad_token,pad_genre_token=pad_genre_token)\n",
    "val_dataset = GRUDataset(val_history,genre_df=ml_movie_df,mode='eval',max_length=max_length,pad_token=pad_token,pad_genre_token=pad_genre_token)\n",
    "test_dataset = GRUDataset(test_history,genre_df=ml_movie_df,mode='eval',max_length=max_length,pad_token=pad_token,pad_genre_token=pad_genre_token)\n",
    "\n",
    "# create the train,validation, and test pytorch dataloader objects\n",
    "train_dl = DataLoader(train_dataset,batch_size = batch_size,shuffle=True)\n",
    "val_dl = DataLoader(val_dataset,batch_size=64)\n",
    "test_dl = DataLoader(test_dataset,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert dim: 768\n",
      "Genre dim: 0\n",
      "Pad Token: 3416\n",
      "Pad Genre Token: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Bert dim: {:d}\".format(bert_dim))\n",
    "print(\"Genre dim: {:d}\".format(genre_dim))\n",
    "print(\"Pad Token: {}\".format(pad_token))\n",
    "print(\"Pad Genre Token: {}\".format(pad_genre_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------Model Initialization----------------------#\n",
    "\n",
    "# initialize gru4rec model with arguments specified earlier\n",
    "if model_type == \"feature_add\":\n",
    "    model = gru4recF(embedding_dim=embedding_dim,\n",
    "             hidden_dim=hidden_dim,\n",
    "             output_dim=output_dim,\n",
    "             genre_dim=genre_dim,\n",
    "             batch_first=True,\n",
    "             max_length=max_length,\n",
    "             pad_token=pad_token,\n",
    "             pad_genre_token=pad_genre_token,\n",
    "             bert_dim=bert_dim,\n",
    "             tied = tied,\n",
    "             dropout=dropout)\n",
    "\n",
    "\n",
    "if model_type == \"feature_concat\":\n",
    "    model = gru4recFC(embedding_dim=embedding_dim,\n",
    "             hidden_dim=hidden_dim,\n",
    "             output_dim=output_dim,\n",
    "             genre_dim=genre_dim,\n",
    "             batch_first=True,\n",
    "             max_length=max_length,\n",
    "             pad_token=pad_token,\n",
    "             pad_genre_token=pad_genre_token,\n",
    "             bert_dim=bert_dim,\n",
    "             tied = tied,\n",
    "             dropout=dropout)\n",
    "\n",
    "if model_type == \"vanilla\":\n",
    "    model = gru4rec_vanilla(hidden_dim=hidden_dim,\n",
    "                            output_dim=output_dim,\n",
    "                            batch_first=True,\n",
    "                            max_length=max_length,\n",
    "                            pad_token=pad_token,\n",
    "                            tied=tied,\n",
    "                            embedding_dim=embedding_dim,\n",
    "                           device=device)\n",
    "\n",
    "if model_type ==\"feature_only\":\n",
    "    model = gru4rec_feature(hidden_dim=hidden_dim,\n",
    "                            output_dim=output_dim,\n",
    "                            batch_first=True,\n",
    "                            max_length=max_length,\n",
    "                            pad_token=pad_token,\n",
    "                            bert_dim=bert_dim)\n",
    "\n",
    "if model_type == \"conv\":\n",
    "    model = gru4rec_conv(embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 batch_first=True,\n",
    "                 max_length=200,\n",
    "                 pad_token=0,\n",
    "                 dropout=0,\n",
    "                 window=3,\n",
    "                 tied=tied)\n",
    "    \n",
    "if model_type == \"nextitnet\":\n",
    "    model = NextItNet(embedding_dim=embedding_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      hidden_layers=hidden_layers,\n",
    "                      dilations=dilations,\n",
    "                      pad_token=n_items,\n",
    "                      max_len=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bert_dim != 0:\n",
    "    model.init_weight(reset_object,feature_embed)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Adam optimizer with gru4rec model parameters\n",
    "if train_method != \"normal\":\n",
    "    optimizer_features = torch.optim.Adam([param for name,param in model.named_parameters() if ((\"movie\" not in name) or (\"plot_embedding\" in name) or (\"genre\" in name)) ],\n",
    "                                          lr=lr_alternate,weight_decay=reg)\n",
    "    \n",
    "    optimizer_ids = torch.optim.Adam([param for name,param in model.named_parameters() if (\"plot\" not in name) and (\"genre\" not in name)],\n",
    "                                     lr=lr,weight_decay=reg)\n",
    "\n",
    "elif train_method == \"normal\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=reg)\n",
    "    \n",
    "if freeze_plot and bert_dim !=0:\n",
    "    model.plot_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3416\n"
     ]
    }
   ],
   "source": [
    "if loss_type == \"XE\":\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=n_items)\n",
    "    \n",
    "elif loss_type == \"BPR\":\n",
    "    loss_fn = BPRLoss(user_history = user_history,\n",
    "                      n_items = n_items, \n",
    "                      df = ml_1m,\n",
    "                      device = device, \n",
    "                      samples=num_neg_samples)\n",
    "\n",
    "elif loss_type == \"BPR_MAX\":\n",
    "    loss_fn = BPRMaxLoss(user_history = user_history,\n",
    "                      n_items = n_items, \n",
    "                      df = ml_1m,\n",
    "                      device = device,\n",
    "                      reg = reg_bpr,\n",
    "                      samples=num_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Creating Hit@10 Metric Object ==========\n"
     ]
    }
   ],
   "source": [
    "Recall_Object = Recall_E_prob(ml_1m,user_history,n_users,n_items,k=k,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Baseline POP results: \",Recall_Object.popular_baseline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_hit = Recall_Object(model,train_dl)\n",
    "#validation_hit = Recall_Object(model,val_dl)\n",
    "#testing_hit = Recall_Object(model,test_dl)\n",
    "#print(\"Training Hits@{:d}: {:.2f}\".format(k,training_hit))\n",
    "#print(\"Validation Hits@{:d}: {:.2f}\".format(k,validation_hit))\n",
    "#print(\"Testing Hits@{:d}: {:.2f}\".format(k,testing_hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:57<00:00,  1.65it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Training Loss: 0.47140\n",
      "Train Hits \t @10: 0.76887 \t @5 : 0.64768 \t @1 : 0.31937\n",
      "Train ndcg \t @10: 0.53287 \t @5 : 0.49356 \t @1 : 0.31937\n",
      "Train mrr \t 0.46924\n",
      "Valid Hits \t @10: 0.67533 \t @5 : 0.54884 \t @1 : 0.24503\n",
      "Valid ndcg \t @10: 0.44542 \t @5 : 0.40432 \t @1 : 0.24503\n",
      "Valid mrr \t 0.38670\n",
      "Test Hits \t @10: 0.62765 \t @5 : 0.50844 \t @1 : 0.23460\n",
      "Test ndcg \t @10: 0.41724 \t @5 : 0.37868 \t @1 : 0.23460\n",
      "Test mrr \t 0.36651\n",
      "==================== Epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:01<00:00,  1.53it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Training Loss: 0.35448\n",
      "Train Hits \t @10: 0.81639 \t @5 : 0.70795 \t @1 : 0.36887\n",
      "Train ndcg \t @10: 0.58508 \t @5 : 0.54978 \t @1 : 0.36887\n",
      "Train mrr \t 0.52046\n",
      "Valid Hits \t @10: 0.69156 \t @5 : 0.57252 \t @1 : 0.26407\n",
      "Valid ndcg \t @10: 0.46582 \t @5 : 0.42727 \t @1 : 0.26407\n",
      "Valid mrr \t 0.40777\n",
      "Test Hits \t @10: 0.65530 \t @5 : 0.53361 \t @1 : 0.24354\n",
      "Test ndcg \t @10: 0.43653 \t @5 : 0.39713 \t @1 : 0.24354\n",
      "Test mrr \t 0.38199\n",
      "==================== Epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:01<00:00,  1.55it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.36397\n",
      "Train Hits \t @10: 0.81407 \t @5 : 0.69735 \t @1 : 0.35464\n",
      "Train ndcg \t @10: 0.57474 \t @5 : 0.53664 \t @1 : 0.35464\n",
      "Train mrr \t 0.50787\n",
      "Valid Hits \t @10: 0.68841 \t @5 : 0.55977 \t @1 : 0.25480\n",
      "Valid ndcg \t @10: 0.45792 \t @5 : 0.41626 \t @1 : 0.25480\n",
      "Valid mrr \t 0.39872\n",
      "Test Hits \t @10: 0.65017 \t @5 : 0.53113 \t @1 : 0.23974\n",
      "Test ndcg \t @10: 0.43083 \t @5 : 0.39245 \t @1 : 0.23974\n",
      "Test mrr \t 0.37615\n",
      "==================== Epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:58<00:00,  1.61it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Training Loss: 0.31804\n",
      "Train Hits \t @10: 0.84321 \t @5 : 0.73825 \t @1 : 0.39470\n",
      "Train ndcg \t @10: 0.61262 \t @5 : 0.57857 \t @1 : 0.39470\n",
      "Train mrr \t 0.54707\n",
      "Valid Hits \t @10: 0.70480 \t @5 : 0.58195 \t @1 : 0.26391\n",
      "Valid ndcg \t @10: 0.47107 \t @5 : 0.43108 \t @1 : 0.26391\n",
      "Valid mrr \t 0.40993\n",
      "Test Hits \t @10: 0.66639 \t @5 : 0.54205 \t @1 : 0.25712\n",
      "Test ndcg \t @10: 0.44725 \t @5 : 0.40681 \t @1 : 0.25712\n",
      "Test mrr \t 0.39181\n",
      "==================== Epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:59<00:00,  1.59it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.34761\n",
      "Train Hits \t @10: 0.81457 \t @5 : 0.70497 \t @1 : 0.36225\n",
      "Train ndcg \t @10: 0.58108 \t @5 : 0.54542 \t @1 : 0.36225\n",
      "Train mrr \t 0.51619\n",
      "Valid Hits \t @10: 0.68891 \t @5 : 0.56490 \t @1 : 0.25530\n",
      "Valid ndcg \t @10: 0.45650 \t @5 : 0.41660 \t @1 : 0.25530\n",
      "Valid mrr \t 0.39697\n",
      "Test Hits \t @10: 0.64834 \t @5 : 0.53493 \t @1 : 0.24421\n",
      "Test ndcg \t @10: 0.43350 \t @5 : 0.39657 \t @1 : 0.24421\n",
      "Test mrr \t 0.38035\n",
      "==================== Epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:00<00:00,  1.57it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Training Loss: 0.31208\n",
      "Train Hits \t @10: 0.84619 \t @5 : 0.74454 \t @1 : 0.39222\n",
      "Train ndcg \t @10: 0.61386 \t @5 : 0.58067 \t @1 : 0.39222\n",
      "Train mrr \t 0.54783\n",
      "Valid Hits \t @10: 0.70762 \t @5 : 0.58924 \t @1 : 0.26755\n",
      "Valid ndcg \t @10: 0.47579 \t @5 : 0.43744 \t @1 : 0.26755\n",
      "Valid mrr \t 0.41543\n",
      "Test Hits \t @10: 0.67136 \t @5 : 0.55795 \t @1 : 0.26457\n",
      "Test ndcg \t @10: 0.45651 \t @5 : 0.41960 \t @1 : 0.26457\n",
      "Test mrr \t 0.40233\n",
      "==================== Epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:01<00:00,  1.55it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.34373\n",
      "Train Hits \t @10: 0.82384 \t @5 : 0.70629 \t @1 : 0.34619\n",
      "Train ndcg \t @10: 0.57568 \t @5 : 0.53749 \t @1 : 0.34619\n",
      "Train mrr \t 0.50576\n",
      "Valid Hits \t @10: 0.69652 \t @5 : 0.56490 \t @1 : 0.24818\n",
      "Valid ndcg \t @10: 0.45831 \t @5 : 0.41552 \t @1 : 0.24818\n",
      "Valid mrr \t 0.39644\n",
      "Test Hits \t @10: 0.66209 \t @5 : 0.53907 \t @1 : 0.24752\n",
      "Test ndcg \t @10: 0.43883 \t @5 : 0.39891 \t @1 : 0.24752\n",
      "Test mrr \t 0.38289\n",
      "==================== Epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:01<00:00,  1.55it/s]\n",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Training Loss: 0.31211\n",
      "Train Hits \t @10: 0.84901 \t @5 : 0.74371 \t @1 : 0.38576\n",
      "Train ndcg \t @10: 0.61204 \t @5 : 0.57768 \t @1 : 0.38576\n",
      "Train mrr \t 0.54417\n",
      "Valid Hits \t @10: 0.71060 \t @5 : 0.58576 \t @1 : 0.27368\n",
      "Valid ndcg \t @10: 0.47937 \t @5 : 0.43893 \t @1 : 0.27368\n",
      "Valid mrr \t 0.41945\n",
      "Test Hits \t @10: 0.68030 \t @5 : 0.56358 \t @1 : 0.26606\n",
      "Test ndcg \t @10: 0.45982 \t @5 : 0.42206 \t @1 : 0.26606\n",
      "Test mrr \t 0.40371\n",
      "==================== Epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:59<00:00,  1.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-966b81f517a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtraining_hit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_ndcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecall_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mvalidation_hit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_ndcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecall_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtesting_hit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting_ndcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting_mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecall_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local2/mlpotter/attentive-session-based-recs/metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, dataloader, mode)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_negatives\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0;31m#topk_items = outputs[i,x_lens[i].item()-1,sample_negatives].argsort(0,descending=True)[:self.k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------Training Initialization----------------------#\n",
    "max_train_hit = (0,0,0)\n",
    "max_val_hit = (0,0,0)\n",
    "max_test_hit = (0,0,0)\n",
    "\n",
    "max_train_ndcg = (0,0,0)\n",
    "max_val_ndcg = (0,0,0)\n",
    "max_test_ndcg = (0,0,0)\n",
    "\n",
    "max_train_mrr = 0\n",
    "max_val_mrr = 0\n",
    "max_test_mrr = 0\n",
    "i = 0;\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"=\"*20,\"Epoch {}\".format(epoch+1),\"=\"*20)\n",
    "    \n",
    "    model.train()  \n",
    "    \n",
    "    running_loss = 0\n",
    "\n",
    "    for j,data in enumerate(tqdm(train_dl,position=0,leave=True)):\n",
    "        \n",
    "        if train_method != \"normal\":\n",
    "            optimizer_features.zero_grad()\n",
    "            optimizer_ids.zero_grad()\n",
    "            \n",
    "        elif train_method == \"normal\": \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if genre_dim != 0:            \n",
    "            inputs,genre_inputs,labels,x_lens,uid = data\n",
    "            outputs = model(x=inputs.to(device),x_lens=x_lens.squeeze().tolist(),x_genre=genre_inputs.to(device))\n",
    "        \n",
    "        elif genre_dim == 0:\n",
    "            inputs,labels,x_lens,uid = data \n",
    "            outputs = model(x=inputs.to(device),x_lens=x_lens.squeeze().tolist())\n",
    "       \n",
    "        if tied:\n",
    "            outputs_ignore_pad = outputs[:,:,:-1]\n",
    "            if loss_type == \"XE\":\n",
    "                loss = loss_fn(outputs_ignore_pad.view(-1,outputs_ignore_pad.size(-1)),labels.view(-1).to(device))\n",
    "            elif loss_type == \"BPR\" or loss_type == \"BPR_MAX\":\n",
    "                loss = loss_fn(outputs,labels.to(device),x_lens,uid)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            if loss_type == \"XE\":\n",
    "                loss = loss_fn(outputs.view(-1,outputs.size(-1)),labels.view(-1).to(device))\n",
    "            elif loss_type == \"BPR\" or loss_type == \"BPR_MAX\":   \n",
    "                loss = loss_fn(outputs,labels.to(device),x_lens,uid)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        if train_method != \"normal\":\n",
    "            if train_method == \"interleave\":\n",
    "                # interleave on the epochs\n",
    "                if (j+1) % 2 == 0:\n",
    "                    optimizer_features.step()\n",
    "                else:\n",
    "                    optimizer_ids.step()\n",
    "\n",
    "            elif train_method == \"alternate\":\n",
    "                if (epoch+1) % 2 == 0:\n",
    "                    optimizer_features.step()\n",
    "                else:\n",
    "                    optimizer_ids.step()\n",
    "        \n",
    "    \n",
    "                    \n",
    "        elif train_method == \"normal\":\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.detach().cpu().item()\n",
    "\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    training_hit,training_ndcg,training_mrr = Recall_Object(model,train_dl,\"train\")\n",
    "    validation_hit,validation_ndcg,validation_mrr = Recall_Object(model,val_dl,\"validation\")\n",
    "    testing_hit,testing_ndcg,testing_mrr = Recall_Object(model,test_dl,\"test\")\n",
    "    \n",
    "    if max_val_mrr < validation_mrr:\n",
    "        max_val_hit = validation_hit\n",
    "        max_test_hit = testing_hit\n",
    "        max_train_hit = training_hit\n",
    "        \n",
    "        max_train_ndcg = training_ndcg\n",
    "        max_val_ndcg = validation_ndcg\n",
    "        max_test_ndcg = testing_ndcg\n",
    "        \n",
    "        max_train_mrr = training_mrr\n",
    "        max_val_mrr = validation_mrr\n",
    "        max_test_mrr = testing_mrr\n",
    "        \n",
    "        torch.save(model.state_dict(),\"best_model_{}.pt\".format(size))\n",
    "        print(\"BEST MODEL PERFORMANCE\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Training Loss: {:.5f}\".format(running_loss/len(train_dl)))\n",
    "    \n",
    "    print(\"Train Hits \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*training_hit))\n",
    "    print(\"Train ndcg \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*training_ndcg))\n",
    "    print(\"Train mrr \\t {:.5f}\".format(training_mrr))\n",
    "\n",
    "\n",
    "    print(\"Valid Hits \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*validation_hit))\n",
    "    print(\"Valid ndcg \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*validation_ndcg))\n",
    "    print(\"Valid mrr \\t {:.5f}\".format(validation_mrr))\n",
    "\n",
    "    print(\"Test Hits \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*testing_hit))\n",
    "    print(\"Test ndcg \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*testing_ndcg))\n",
    "    print(\"Test mrr \\t {:.5f}\".format(testing_mrr))\n",
    "    \n",
    "print(\"=\"*100)\n",
    "print(\"Maximum Training Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_train_hit))\n",
    "print(\"Maximum Validation Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_val_hit))\n",
    "print(\"Maximum Testing Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_test_hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"Maximum Train Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_train_hit))\n",
    "print(\"Maximum Valid Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_val_hit))\n",
    "print(\"Maximum Test Hit \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_test_hit))\n",
    "\n",
    "print(\"Maximum Train NDCG \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_train_ndcg))\n",
    "print(\"Maximum Valid NDCG \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_val_ndcg))\n",
    "print(\"Maximum Test NDCG \\t @10: {:.5f} \\t @5 : {:.5f} \\t @1 : {:.5f}\".format(*max_test_ndcg))\n",
    "\n",
    "print(\"Maximum Train MRR \\t {:.5f}\".format(max_train_mrr))\n",
    "print(\"Maximum Valid MRR \\t {:.5f}\".format(max_val_mrr))\n",
    "print(\"Maximum Test MRR \\t {:.5f}\".format(max_test_mrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some visual examples ... pray to god they are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df =pd.read_csv(\"data/movielens-1m/movies-1m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_1m.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mode = 'validation'\n",
    "    model.eval()\n",
    "    for data in val_dl:\n",
    "        if model.genre_dim != 0:            \n",
    "            inputs,genre_inputs,labels,x_lens,uid = data\n",
    "            outputs = model(x=inputs.to(Recall_Object.device),x_lens=x_lens.squeeze().tolist(),x_genre=genre_inputs.to(Recall_Object.device))\n",
    "\n",
    "        else:\n",
    "            inputs,labels,x_lens,uid = data\n",
    "            outputs = model(x=inputs.to(Recall_Object.device),x_lens=x_lens.squeeze().tolist())\n",
    "            \n",
    "        for i,uid in enumerate(uid.squeeze()):\n",
    "            history = Recall_Object.user_history[uid.item()]\n",
    "\n",
    "            if mode == \"train\":\n",
    "                history = set(history[:-2])\n",
    "\n",
    "            if mode == \"validation\":\n",
    "                history = set(history[:-1])\n",
    "\n",
    "            if mode == \"test\":\n",
    "                history = set(history)\n",
    "\n",
    "\n",
    "            #sample_negatives = []\n",
    "            sample_negatives = [labels[i,x_lens[i].item()-1].item()]\n",
    "            while len(sample_negatives) < 101:\n",
    "\n",
    "                sampled_ids = np.random.choice(Recall_Object.n_items, 100, replace=False, p=Recall_Object.p).tolist()\n",
    "                sampled_ids = [x for x in sampled_ids if x not in history and x not in sample_negatives]\n",
    "                sample_negatives.extend(sampled_ids[:])\n",
    "\n",
    "            #sample_negatives = sample_negatives[:100].copy()\n",
    "            sample_negatives = sample_negatives[:101].copy()\n",
    "            #sample_negatives.append(labels[i,x_lens[i].item()-1].item())\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                        \n",
    "            rank = torch.where(outputs[i,x_lens[i].item()-1,sample_negatives].argsort(descending=True)==0)[0].item()  \n",
    "\n",
    "            \n",
    "            movies_ranked = np.array(sample_negatives)[outputs[i,x_lens[i].item()-1,sample_negatives].argsort(descending=True).cpu().numpy()]\n",
    "            gt_movie = labels[i,x_lens[i].item()-1].item()\n",
    "            user_id = uid.item()\n",
    "            user_input_session = inputs[i][inputs[i] != 3706].cpu().numpy()\n",
    "            \n",
    "            print(\"User ID: \",user_id)\n",
    "            print(\"Rankings at t+1: \",movies_ranked)\n",
    "            print(\"GT Item: \",gt_movie)\n",
    "            print(\"GT Item Rank: \",rank)\n",
    "            print(\"User Session: \",user_input_session)\n",
    "            print(\"Last 20 movies: \\n\",movie_df.loc[user_input_session,['title','genres']][-20:])    #movie_df.title[user_input_session][-20:].values)\n",
    "            print(\"Top 10 recommended:\\n\",movie_df.loc[movies_ranked,['title','genres']][:10])\n",
    "\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.title[movies_ranked][:10].values,movie_df.genres[movies_ranked][:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.loc[movies_ranked,['title','genres']][:10] #  .title[movies_ranked][:10].values,movie_df.genres[movies_ranked][:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example = [1050,0,2120,2072,711,2073,351,2285,3542,3682,3685,3327,1346,2286] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example_len = torch.LongTensor([len(toy_example)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example = torch.LongTensor([toy_example + [3706] * (200-toy_example_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(x=toy_example.to(Recall_Object.device),x_lens=toy_example_len.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df[movie_df.genres == \"Animation|Children's|Comedy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.iloc[ [1050,0,2120,2072,711,2073,351,2285,3542,3682,3685,3327,1346,2286] ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.where(outputs.squeeze()[toy_example_len].squeeze().argsort(descending=True) == 2286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.iloc[3582]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movie_df.iloc[outputs.squeeze()[toy_example_len].squeeze().argsort(descending=True).cpu().numpy()][:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccf759c9a31416883782fb07d421a0d960c996c881b7ffce781f6066ae1dc2cf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
